import os
import json
import numpy as np
import pandas as pd
import torch
import nibabel as nib
from PIL import Image
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.feature_selection import RFE
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns


LABELS_XLSX = r'C:\Users\95602\Desktop\ultrasound-contrastivemodels-klr-us-rna\TCIA\TCIA\TCIA-cohorts1.xlsx'
bbox_json_path = r'C:\Users\95602\PycharmProjects\PythonProject2\bbox_coords.json'
image_directory = r'C:\Users\95602\Desktop\ultrasound-contrastivemodels-klr-us-rna\TCIA\TCIA'
MODEL_PATH = "clip_model_vit_contrastive_pretrained.pth"
N_CHANNELS = 16
IMG_SIZE = 224
EMBED_DIM = 512
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


df_label = pd.read_excel(LABELS_XLSX, dtype=str)
df_label['PDL1'] = df_label['PDL1'].astype(float)  # 0/1
patient_id_list = df_label['Patient.ID'].tolist()
pdl1_label_list = df_label['PDL1'].tolist()

#  bbox
with open(bbox_json_path, 'r') as f:
    bbox_coords = json.load(f)

nifti_files = {}
for root, _, files in os.walk(image_directory):
    for fname in files:
        if fname.lower().endswith('.nii') or fname.lower().endswith('.nii.gz'):
            base = os.path.splitext(os.path.splitext(fname)[0])[0]
            nifti_files[base] = os.path.join(root, fname)

def sample_slices(total_slices, n=N_CHANNELS):
    if total_slices < n:
        idxs = list(range(total_slices)) + [total_slices // 2] * (n - total_slices)
        return idxs[:n]
    else:
        return np.linspace(0, total_slices - 1, n, dtype=int)

# model
from model import ResNetMultiChannel
resnet_encoder = ResNetMultiChannel(n_channels=N_CHANNELS, embedding_dim=EMBED_DIM).to(DEVICE)
state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
if any(k.startswith("image_encoder.") for k in state_dict.keys()):
    image_encoder_state = {k.replace("image_encoder.", ""): v for k, v in state_dict.items() if k.startswith("image_encoder.")}
    resnet_encoder.load_state_dict(image_encoder_state, strict=False)
elif "image_encoder" in state_dict:
    resnet_encoder.load_state_dict(state_dict["image_encoder"], strict=False)
else:
    resnet_encoder.load_state_dict(state_dict, strict=False)
resnet_encoder.eval()

def extract_ct_embedding(patient_id):
    matches = []
    for ext in [".nii.gz", ".nii"]:
        base = patient_id
        if base in nifti_files and nifti_files[base].endswith(ext):
            matches.append(nifti_files[base])
    if not matches:
        return None
    img_path = matches[0]
    seg_key = 'seg' + patient_id.replace('-', '') + '.nii.gz'
    if seg_key not in bbox_coords:
        return None
    try:
        vol = nib.load(img_path).get_fdata()
        bbox = bbox_coords[seg_key]
        x0, x1 = sorted((bbox['x_min'], bbox['x_max']))
        y0, y1 = sorted((bbox['y_min'], bbox['y_max']))
        z0, z1 = sorted((bbox['z_min'], bbox['z_max']))
        roi = vol[x0:x1, y0:y1, z0:z1]
        if roi.shape[2] == 0:
            return None
        slice_idxs = sample_slices(roi.shape[2], n=N_CHANNELS)
        imgs = [roi[:, :, i] for i in slice_idxs]
        imgs = np.stack(imgs, axis=0)
        imgs = (imgs - imgs.min()) / (imgs.max() - imgs.min() + 1e-8)
        imgs_resized = []
        for i in range(N_CHANNELS):
            img = Image.fromarray((imgs[i] * 255).astype(np.uint8))
            img = img.resize((IMG_SIZE, IMG_SIZE))
            imgs_resized.append(np.array(img, dtype=np.float32) / 255.0)
        imgs_tensor = torch.tensor(np.stack(imgs_resized, axis=0), dtype=torch.float).unsqueeze(0).to(DEVICE)
        with torch.no_grad():
            embedding = resnet_encoder(imgs_tensor)
        return embedding.cpu().numpy().squeeze()
    except Exception as e:
        print(f"wrong{patient_id}: {e}")
        return None

# feature
X, Y = [], []
for pid, label in zip(patient_id_list, pdl1_label_list):
    emb = extract_ct_embedding(pid)
    if emb is not None:
        X.append(emb)
        Y.append(int(label))
X = np.array(X)
Y = np.array(Y)

print(f'sample: {len(X)}, p: {sum(Y)}, n: {len(Y)-sum(Y)}')



# feature
def rfe_select(X, Y, n_features=16):
    estimator = LogisticRegression(max_iter=1000, solver='liblinear')
    selector = RFE(estimator, n_features_to_select=min(n_features, X.shape[1]))
    X_new = selector.fit_transform(X, Y)
    return X_new

feature_methods = {
    'Raw': lambda X, Y: X,
    'PCA-8': lambda X, Y: PCA(n_components=min(8, X.shape[1])).fit_transform(X),
    'PCA-16': lambda X, Y: PCA(n_components=min(16, X.shape[1])).fit_transform(X),
    'PCA-32': lambda X, Y: PCA(n_components=min(32, X.shape[1])).fit_transform(X),
    'RFE-16': lambda X, Y: rfe_select(X, Y, n_features=16),
}

model_dict = {
    'LR': LogisticRegression(max_iter=2000, solver='liblinear'),
    'RF': RandomForestClassifier(n_estimators=200, random_state=42),
    'SVM': SVC(probability=True, kernel='rbf', random_state=42),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Ridge': RidgeClassifier(),
    'MLP': MLPClassifier(hidden_layer_sizes=(64,), max_iter=1000, random_state=42),
}

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

results = np.zeros((len(model_dict), len(feature_methods)))

for i, (model_name, model) in enumerate(model_dict.items()):
    for j, (feat_name, feat_func) in enumerate(feature_methods.items()):
        aucs = []
        for train_idx, test_idx in skf.split(X_scaled, Y):
            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]
            y_train, y_test = Y[train_idx], Y[test_idx]
            
            X_train_f = feat_func(X_train, y_train)
            
            if feat_name.startswith('PCA'):
                pca = PCA(n_components=X_train_f.shape[1])
                pca.fit(X_train)
                X_test_f = pca.transform(X_test)
            elif feat_name.startswith('RFE'):
                estimator = LogisticRegression(max_iter=1000, solver='liblinear')
                selector = RFE(estimator, n_features_to_select=X_train_f.shape[1])
                selector.fit(X_train, y_train)
                X_test_f = selector.transform(X_test)
            else:
                X_test_f = X_test
            
            try:
                model.fit(X_train_f, y_train)
                if hasattr(model, "predict_proba"):
                    y_prob = model.predict_proba(X_test_f)[:, 1]
                else:
                    y_prob = model.decision_function(X_test_f)
                    if y_prob.ndim > 1:
                        y_prob = y_prob[:, 0]
                auc = roc_auc_score(y_test, y_prob)
                aucs.append(auc)
            except Exception as e:
                print(f"Model {model_name}, Feature {feat_name} error: {e}")
                aucs.append(np.nan)
        results[i, j] = np.nanmean(aucs)


plt.figure(figsize=(10, 6))
sns.heatmap(
    results,
    annot=True, fmt=".3f", cmap="YlGnBu",
    xticklabels=list(feature_methods.keys()),
    yticklabels=list(model_dict.keys())
)
plt.xlabel("Feature Selection / Dimensionality Reduction")
plt.ylabel("Classifier")
plt.title("Five-fold ROC-AUC Heatmap for PD-L1 Prediction (CT features)")
plt.tight_layout()
plt.show()
